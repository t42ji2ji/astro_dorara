---
title: "選擇題 vs 實作題：為什麼選對了還是不會？"
description: "設計讓學員真正動手做的練習"
order: 3
---

import Comparison from '~/components/learn/Comparison.astro'
import Exercise from '~/components/learn/Exercise.astro'
import Answer from '~/components/learn/Answer.astro'
import Template from '~/components/learn/Template.astro'
import Callout from '~/components/learn/Callout.astro'
import SelfCheck from '~/components/learn/SelfCheck.astro'

## 這個單元你會學會做什麼

為你的目標行為，設計一個**有情境、讓學員產出**的練習活動。

🟢 基礎 ｜ 約 30 分鐘

---

## 快速說明

大多數課程的**練習**其實是**測驗**。

測驗長這樣：

```
以下哪個是正確的 Git 指令？
A. git branch new-feature
B. git new branch feature
C. git create branch
D. 以上皆非
```

學員選對了，代表他**認得**正確答案。但這不代表他自己能寫出來。

Cathy Moore 對好課程有一個精準的描述：

> 好的課程是「一連串的活動」，不是「偶爾被測驗打斷的簡報」。

練習應該讓學員**做他日後會做的事**，而且要讓他們**主動拉取資訊**，而不是被動接收。

### 好的練習有三個要素

1. **情境**：一個具體的場景，像真實工作會遇到的
2. **任務**：學員要產出東西，不是選答案
3. **後果型反饋**：告訴學員**這樣做會怎樣**，不只是對或錯

### 範例對比

<Comparison badLabel="測驗型" goodLabel="情境型">
  <Fragment slot="bad">
    **問題**：建立 Git 分支的正確指令是？

    A. git branch new-feature
    B. git new branch feature
    C. git create branch
  </Fragment>
  <Fragment slot="good">
    **情境**：你接到一個新任務：修復登入頁面的 bug。主管說：「在新分支上改，不要動到 main。」

    **任務**：寫出你會執行的 Git 指令。
  </Fragment>
</Comparison>

差別在哪？

測驗型：學員認出正確答案，但可能不知道**為什麼**或**什麼時候用**。

情境型：學員經歷了一個迷你版的真實情境。他要自己決定怎麼做，而且能從反饋中學到細節（比如**建了分支要記得切過去**）。

### 後果型反饋的威力

注意上面範例的反饋不是說「你答對了」或「你答錯了」，而是說「如果你這樣做，會發生什麼事」。

這叫**後果型反饋**。它模擬真實世界：在工作中，沒有人會跳出來說「答對了！」你只會看到你的行動造成的後果。

後果型反饋比對錯判斷更有學習效果，因為它：
- 讓學員理解**為什麼**某個做法比較好
- 幫助學員在類似情境中舉一反三
- 把學習和真實工作連結起來

設計反饋時，問自己：「在真實工作中，這個行動會導致什麼結果？」然後把那個結果告訴學員。

---

## 練習

<Exercise title="練習：設計情境型練習" level={3}>
  <Fragment slot="scenario">
    你正在設計一堂 **Prompt Engineering** 入門課。目標行為是：**寫出讓 AI 正確完成指定任務的 prompt**。

    你看了別人的課程，發現練習都是選擇題：

    ```
    以下哪個是好的 prompt？
    A. 翻譯這段文字
    B. 請將以下文字翻譯成繁體中文，保持專業語氣
    C. 幫我翻譯
    D. translate this
    ```

    你知道這不夠。學員選對了 B，不代表他自己能寫出 B 這種品質的 prompt。
  </Fragment>
  <Fragment slot="task">
    設計一個情境型練習，讓學員真的**寫** prompt，而不是**選** prompt。

    請包含：
    1. 情境（具體場景）
    2. 任務（學員要產出什麼）
    3. 參考答案和解說
  </Fragment>
</Exercise>

<Template title="你的練習設計">
【情境】



【任務】



【參考答案與解說】


</Template>

<Answer title="參考設計">
**情境**

你是行銷部門的新人。主管丟給你一份 20 頁的市場調查報告，說：「下午開會要用，幫我整理個摘要。」

你決定用 AI 來幫忙，但直接貼上去然後說「整理一下」，結果 AI 給你一堆你不需要的東西。

**任務**

寫一個 prompt，讓 AI 幫你把這份報告整理成：
- 3-5 個關鍵發現
- 每點一句話
- 適合在會議上口頭報告

**參考答案**

```
請將以下市場調查報告整理成摘要：
- 列出 3-5 個最重要的發現
- 每個發現用一句話描述（不超過 30 字）
- 使用適合口頭報告的語氣

報告內容：
[貼上報告]
```

**解說**

這個 prompt 有效的原因：
1. 明確數量：**3-5 個**，不是**幾個**
2. 限制長度：**一句話**、**不超過 30 字**
3. 指定用途：**適合口頭報告**，AI 會調整語氣

常見問題：
- 沒說數量 → AI 可能列 10 個
- 沒限長度 → AI 可能每點寫一段
- 沒說用途 → 語氣可能太書面
</Answer>

---

## 設計練習的檢查表

<SelfCheck title="你設計的練習">
  <li>有情境：場景夠具體，學員能想像自己在那個情況</li>
  <li>要產出：學員需要寫/做/建立東西，不只是選答案</li>
  <li>像真的：這個情境在真實工作中會發生</li>
  <li>有後果：反饋說明「這樣做會怎樣」，不只是對錯</li>
</SelfCheck>

---

## 常見問題

<Callout type="info" title="這樣設計練習好花時間，有比較快的方法嗎？">
沒有。

好的練習本來就需要時間設計。但換個角度想：你花 2 小時設計一個好練習，學員真的學會了。比起花 30 分鐘寫一堆選擇題，學員看過就忘，哪個划算？
</Callout>

<Callout type="info" title="學員答案千百種，怎麼給反饋？">
提供**參考答案**而不是**標準答案**。

列出好的答案有哪些特徵，讓學員自己對照。比起**你錯了**，**你的答案缺少 X 特徵**更有學習效果。
</Callout>

<Callout type="info" title="線上課程怎麼做這種開放式練習？">
幾個做法：
1. 讓學員寫完後，自己對照參考答案
2. 提供**提交後才顯示答案**的機制
3. 建立學員社群，讓他們互相看彼此的答案

不完美，但比選擇題好得多。
</Callout>

---

## 下一步

現在你能設計練習活動了。但你可能會想：**那原本準備的知識內容怎麼辦？**

下一單元，我們來處理這個問題。
